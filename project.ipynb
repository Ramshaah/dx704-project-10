{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 10 Project\n",
        "\n",
        "In this project, you will implement document search within a question and answer database and assess its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4B2Ff6lisqH"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 10 Materials](https://github.com/bu-cds-dx704/dx704-project-10).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEezzKGSdyXB"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQhkdHNFbwLp"
      },
      "source": [
        "## Part 1: Download the SQuAD-explorer Data Set\n",
        "\n",
        "You may use the code provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KDN4uTycILU",
        "outputId": "263d0284-de7d-493e-c40f-92161d739ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SQuAD-explorer'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5563, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 5563 (delta 11), reused 17 (delta 6), pack-reused 5539 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5563/5563), 52.26 MiB | 12.47 MiB/s, done.\n",
            "Resolving deltas: 100% (3563/3563), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rajpurkar/SQuAD-explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W7Cgmz-lVmBF"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kXc87YHZVsOz"
      },
      "outputs": [],
      "source": [
        "with open(\"SQuAD-explorer/dataset/train-v1.1.json\") as fp:\n",
        "    train_data = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYKgEa3V149",
        "outputId": "d512a1ae-7e36-4675-c3b9-05ebea9bf9df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJrdzIqwV3FK",
        "outputId": "78415ac7-f68a-4179-cc19-6ccd18c00b33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data', 'version']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(train_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbru7Z_UV74r",
        "outputId": "5c90d6d6-e0db-459e-fc99-8c59e0d7ee54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvLq8Xo_V-Ji",
        "outputId": "214682af-3013-4c9c-a344-1953dd6e7120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "442"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIaSECnAWBv7",
        "outputId": "d9e182f7-22c8-4f9b-c756-adacde1112ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4bVs4bWJ7l",
        "outputId": "9dc04b5a-0943-4cb2-d78b-c137545a35ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['title', 'paragraphs'])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uIwF0bTeWMEC",
        "outputId": "357ae956-3930-418f-e822-62de93d2fcb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'University_of_Notre_Dame'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"title\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YopAkB-WOTW",
        "outputId": "e2767d66-e39b-40f4-bd42-47a40c9240ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"][0][\"paragraphs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bm3BAIqWRCT",
        "outputId": "da233573-f62c-46ee-9384-16fd6a110ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'qas': [{'answers': [{'answer_start': 515,\n",
              "     'text': 'Saint Bernadette Soubirous'}],\n",
              "   'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              "   'id': '5733be284776f41900661182'},\n",
              "  {'answers': [{'answer_start': 188, 'text': 'a copper statue of Christ'}],\n",
              "   'question': 'What is in front of the Notre Dame Main Building?',\n",
              "   'id': '5733be284776f4190066117f'},\n",
              "  {'answers': [{'answer_start': 279, 'text': 'the Main Building'}],\n",
              "   'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
              "   'id': '5733be284776f41900661180'},\n",
              "  {'answers': [{'answer_start': 381,\n",
              "     'text': 'a Marian place of prayer and reflection'}],\n",
              "   'question': 'What is the Grotto at Notre Dame?',\n",
              "   'id': '5733be284776f41900661181'},\n",
              "  {'answers': [{'answer_start': 92,\n",
              "     'text': 'a golden statue of the Virgin Mary'}],\n",
              "   'question': 'What sits on top of the Main Building at Notre Dame?',\n",
              "   'id': '5733be284776f4190066117e'}]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"paragraphs\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7RL5JTWraU",
        "outputId": "2a09c434-6eb4-4bba-9a60-d323136cfbfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18896"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(len(doc[\"paragraphs\"]) for doc in train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 2: Restructure JSON Data for Processing\n",
        "\n",
        "Parse the file \"SQuAD-explorer/dataset/train-v1.1.json\" above to produce a file \"parsed.tsv\" with columns document_title, paragraph_index, and paragraph_context.\n",
        "The paragraph_index column should be zero-indexed, so zero for the first paragraph of each document.\n",
        "Use pandas `to_csv` method to write the file since there are many quotes and other issues to handle otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QJHSCtWWaLAG"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "      <th>paragraph_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>0</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>1</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>2</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>3</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>4</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             document_title  paragraph_index  \\\n",
              "0  University_of_Notre_Dame                0   \n",
              "1  University_of_Notre_Dame                1   \n",
              "2  University_of_Notre_Dame                2   \n",
              "3  University_of_Notre_Dame                3   \n",
              "4  University_of_Notre_Dame                4   \n",
              "\n",
              "                                   paragraph_context  \n",
              "0  Architecturally, the school has a Catholic cha...  \n",
              "1  As at most other universities, Notre Dame's st...  \n",
              "2  The university is the major seat of the Congre...  \n",
              "3  The College of Engineering was established in ...  \n",
              "4  All of Notre Dame's undergraduate students are...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 2: build parsed.tsv\n",
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "\n",
        "# train_data was already loaded above\n",
        "for doc in train_data[\"data\"]:\n",
        "    title = doc[\"title\"]\n",
        "    for idx, para in enumerate(doc[\"paragraphs\"]):\n",
        "        context = para[\"context\"]\n",
        "        rows.append(\n",
        "            {\n",
        "                \"document_title\": title,\n",
        "                \"paragraph_index\": idx,          # zero-indexed\n",
        "                \"paragraph_context\": context,\n",
        "            }\n",
        "        )\n",
        "\n",
        "parsed_df = pd.DataFrame(rows)\n",
        "parsed_df.to_csv(\"parsed.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "parsed_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9VpBX7aNLP"
      },
      "source": [
        "Submit \"parsed.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7Sr3TdcTqr"
      },
      "source": [
        "## Part 3: Prepare Suitable Paragraph Vectors for Document Search\n",
        "\n",
        "Design and implement paragraph vectors based on their text with length 1024.\n",
        "Note that this will be much smaller than the number of distinct words in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRkun5bA1J6c"
      },
      "source": [
        "Hint: you can base your vectors on any techniques covered in this module so far.\n",
        "Beware that they will be automatically assessed (along with the question vectors of part 4) to make sure they retain useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v978AkFmdnLD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18896, 1024)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 3 (1/2): create 1024-dim paragraph vectors using TF-IDF\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Read the parsed paragraphs\n",
        "parsed_df = pd.read_csv(\"parsed.tsv\", sep=\"\\t\")\n",
        "\n",
        "# TF-IDF with vocabulary size 1024\n",
        "tfidf = TfidfVectorizer(max_features=1024)\n",
        "paragraph_matrix = tfidf.fit_transform(parsed_df[\"paragraph_context\"])\n",
        "\n",
        "paragraph_matrix.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbZRTxludpHC"
      },
      "source": [
        "Save your paragraph vectors in a file \"paragraph-vectors.tsv.gz\" with columns document_title, paragraph_index, and paragraph_vector_json where paragraph_vector_json is a JSON encoded list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGE7ooGVckTC"
      },
      "source": [
        "Hint: don't forget the \".gz\" extension indicating gzip compression.\n",
        "The Pandas `.to_csv` method will automatically add the compression if you save data with a filename ending in \".gz\", so you just need to pass it the right filename."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nNvDMTE1edGm"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "      <th>paragraph_vector_json</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             document_title  paragraph_index  \\\n",
              "0  University_of_Notre_Dame                0   \n",
              "1  University_of_Notre_Dame                1   \n",
              "2  University_of_Notre_Dame                2   \n",
              "3  University_of_Notre_Dame                3   \n",
              "4  University_of_Notre_Dame                4   \n",
              "\n",
              "                               paragraph_vector_json  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 3 (2/2): save paragraph vectors to paragraph-vectors.tsv.gz\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Convert sparse matrix to dense (n_paragraphs x 1024)\n",
        "paragraph_dense = paragraph_matrix.toarray().astype(float)\n",
        "\n",
        "paragraph_vector_json = [\n",
        "    json.dumps(vec.tolist()) for vec in paragraph_dense\n",
        "]\n",
        "\n",
        "paragraph_vectors_df = pd.DataFrame(\n",
        "    {\n",
        "        \"document_title\": parsed_df[\"document_title\"],\n",
        "        \"paragraph_index\": parsed_df[\"paragraph_index\"],\n",
        "        \"paragraph_vector_json\": paragraph_vector_json,\n",
        "    }\n",
        ")\n",
        "\n",
        "paragraph_vectors_df.to_csv(\n",
        "    \"paragraph-vectors.tsv.gz\", sep=\"\\t\", index=False\n",
        ")\n",
        "\n",
        "paragraph_vectors_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71KxgBp-eeqm"
      },
      "source": [
        "Submit \"paragraph-vectors.tsv.gz\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPL_MR_GeSa1"
      },
      "source": [
        "## Part 4: Encode Question Vectors with the Same Design\n",
        "\n",
        "Read the questions in \"questions.tsv\" and encode them in the same way that you encoded the paragraph vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "75F95fJjpZ3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 1024)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 4 (1/2): encode question vectors with the SAME tfidf as paragraphs\n",
        "import pandas as pd\n",
        "\n",
        "questions_df = pd.read_csv(\"questions.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Use the SAME fitted tfidf object from Part 3\n",
        "question_matrix = tfidf.transform(questions_df[\"question\"])\n",
        "\n",
        "question_matrix.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H5j32O5pb03"
      },
      "source": [
        "Save your question vectors in \"question-vectors.tsv\" with columns question_id and question_vector_json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oLyvhIcYpr06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_vector_json</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id                               question_vector_json\n",
              "0            1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "1            4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2            7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "3           10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "4           13  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 4 (2/2): save question vectors to question-vectors.tsv\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "question_dense = question_matrix.toarray().astype(float)\n",
        "\n",
        "question_vector_json = [\n",
        "    json.dumps(vec.tolist()) for vec in question_dense\n",
        "]\n",
        "\n",
        "question_vectors_df = pd.DataFrame(\n",
        "    {\n",
        "        \"question_id\": questions_df[\"question_id\"],\n",
        "        \"question_vector_json\": question_vector_json,\n",
        "    }\n",
        ")\n",
        "\n",
        "question_vectors_df.to_csv(\n",
        "    \"question-vectors.tsv\", sep=\"\\t\", index=False\n",
        ")\n",
        "\n",
        "question_vectors_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmcWnJUptZN"
      },
      "source": [
        "Submit \"question-vectors.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRDyTUxcvCx"
      },
      "source": [
        "## Part 5: Match Questions to Paragraphs using Nearest Neighbors\n",
        "\n",
        "Match your question vectors to paragraph vectors and identify the top 5 paragraph vectors for each question using nearest neighbors.\n",
        "Specifically, use the Euclidean distance between the vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dJlB2SsMqf1F"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_rank</th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Tuvalu</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Genome</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Bill_%26_Melinda_Gates_Foundation</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Tibet</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id  question_rank                     document_title  \\\n",
              "0            1              1                             Tuvalu   \n",
              "1            1              2                             Genome   \n",
              "2            1              3                          Rajasthan   \n",
              "3            1              4  Bill_%26_Melinda_Gates_Foundation   \n",
              "4            1              5                              Tibet   \n",
              "\n",
              "   paragraph_index  \n",
              "0               49  \n",
              "1                8  \n",
              "2                9  \n",
              "3                6  \n",
              "4               10  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "# Part 5 (1/2): find top-5 nearest paragraphs for each question\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# We assume parsed_df, paragraph_matrix, questions_df, question_matrix\n",
        "# are already in memory from Parts 3 and 4.\n",
        "\n",
        "n_neighbors = 5\n",
        "nn = NearestNeighbors(n_neighbors=n_neighbors, metric=\"euclidean\")\n",
        "nn.fit(paragraph_matrix)\n",
        "\n",
        "distances, indices = nn.kneighbors(question_matrix)\n",
        "\n",
        "rows = []\n",
        "for q_idx, (q_id, neigh_indices) in enumerate(\n",
        "    zip(questions_df[\"question_id\"], indices)\n",
        "):\n",
        "    for rank, p_idx in enumerate(neigh_indices, start=1):\n",
        "        rows.append(\n",
        "            {\n",
        "                \"question_id\": q_id,\n",
        "                \"question_rank\": rank,\n",
        "                \"document_title\": parsed_df.loc[p_idx, \"document_title\"],\n",
        "                \"paragraph_index\": int(parsed_df.loc[p_idx, \"paragraph_index\"]),\n",
        "            }\n",
        "        )\n",
        "\n",
        "matches_df = pd.DataFrame(rows)\n",
        "matches_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvjW3nP-qkSk"
      },
      "source": [
        "Save your top matches in a file \"question-matches.tsv\" with columns question_id, question_rank, document_title, and paragraph_index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "heaNwWMlrAwv"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_rank</th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Tuvalu</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Genome</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Bill_%26_Melinda_Gates_Foundation</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Tibet</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id  question_rank                     document_title  \\\n",
              "0            1              1                             Tuvalu   \n",
              "1            1              2                             Genome   \n",
              "2            1              3                          Rajasthan   \n",
              "3            1              4  Bill_%26_Melinda_Gates_Foundation   \n",
              "4            1              5                              Tibet   \n",
              "\n",
              "   paragraph_index  \n",
              "0               49  \n",
              "1                8  \n",
              "2                9  \n",
              "3                6  \n",
              "4               10  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 5 (2/2): save matches to question-matches.tsv\n",
        "matches_df.to_csv(\"question-matches.tsv\", sep=\"\\t\", index=False)\n",
        "matches_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0m-ogJjrCK8"
      },
      "source": [
        "Submit \"question-matches.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftG5ez0tsyy"
      },
      "source": [
        "## Part 6: Spot Check Question and Paragraph Matches\n",
        "\n",
        "Review the paragraphs matched to the first 5 questions (sorted by question_id ascending).\n",
        "Which paragraph was the worst match for each question?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Part 6: build worst-paragraphs.tsv AFTER manual inspection\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: replace the example rows with your actual choices\n",
        "worst_rows = [\n",
        "    # Example format (replace with real values):\n",
        "    # {\"question_id\": 1, \"document_title\": \"Some_Title\", \"paragraph_index\": 123},\n",
        "    # {\"question_id\": 4, \"document_title\": \"Another_Title\", \"paragraph_index\": 45},\n",
        "]\n",
        "\n",
        "worst_df = pd.DataFrame(worst_rows)\n",
        "worst_df.to_csv(\"worst-paragraphs.tsv\", sep=\"\\t\", index=False)\n",
        "worst_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FqfB5lZ087m"
      },
      "source": [
        "Submit \"worst-paragraphs.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "QUESTION 1: What was the goal of the abuse of region project?\n",
            "\n",
            "  rank 1 | doc=Tuvalu | para_index=49\n",
            "The eastern shoreline of Funafuti Lagoon was modified during World War II when the airfield (what is now Funafuti International Airport) was constructed. The coral base of the atoll was used as fill to create the runway. The resulting borrow pits impacted the fresh-water aquifer. In the low areas of Funafuti the sea water can be seen bubbling up through the porous coral rock to form pools with each high tide. Since 1994 a project has been in development to assess the environmental impact of transporting sand from the lagoon to fill all the borrow pits and low-lying areas on Fongafale. In 2014 the Tuvalu Borrow Pits Remediation (BPR) project was approved in order to fill 10 borrow pits, leaving Tafua Pond, which is a natural pond. The New Zealand Government funded the BPR project. The project was carried out in 2015 with 365,000 sqm of sand being dredged from the lagoon to fill the holes and improve living conditions on the island. This project increase the usable land space on Fongafale by eight per cent.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 2 | doc=Genome | para_index=8\n",
            "Whereas a genome sequence lists the order of every DNA base in a genome, a genome map identifies the landmarks. A genome map is less detailed than a genome sequence and aids in navigating around the genome. The Human Genome Project was organized to map and to sequence the human genome. A fundamental step in the project was the release of a detailed genomic map by Jean Weissenbach and his team at the Genoscope in Paris.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 3 | doc=Rajasthan | para_index=9\n",
            "The Aravalli Range and the lands to the east and southeast of the range are generally more fertile and better watered. This region is home to the Kathiarbar-Gir dry deciduous forests ecoregion, with tropical dry broadleaf forests that include teak, Acacia, and other trees. The hilly Vagad region, home to the cities of Dungarpur and Banswara lies in southernmost Rajasthan, on the border with Gujarat and Madhya Pradesh. With the exception of Mount Abu, Vagad is the wettest region in Rajasthan, and the most heavily forested. North of Vagad lies the Mewar region, home to the cities of Udaipur and Chittaurgarh. The Hadoti region lies to the southeast, on the border with Madhya Pradesh. North of Hadoti and Mewar lies the Dhundhar region, home to the state capital of Jaipur. Mewat, the easternmost region of Rajasthan, borders Haryana and Uttar Pradesh. Eastern and southeastern Rajasthan is drained by the Banas and Chambal rivers, tributaries of the Ganges.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 4 | doc=Bill_%26_Melinda_Gates_Foundation | para_index=6\n",
            "The IJM used the grant money to found \"Project Lantern\" and established an office in the Philippines city of Cebu. In 2010 the results of the project were published, in which the IJM stated that Project Lantern had led to \"an increase in law enforcement activity in sex trafficking cases, an increase in commitment to resolving sex trafficking cases among law enforcement officers trained through the project, and an increase in services – like shelter, counseling and career training – provided to trafficking survivors\". At the time that the results were released, the IJM was exploring opportunities to replicate the model in other regions.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 5 | doc=Tibet | para_index=10\n",
            "The earliest Tibetan historical texts identify the Zhang Zhung culture as a people who migrated from the Amdo region into what is now the region of Guge in western Tibet. Zhang Zhung is considered to be the original home of the Bön religion. By the 1st century BCE, a neighboring kingdom arose in the Yarlung valley, and the Yarlung king, Drigum Tsenpo, attempted to remove the influence of the Zhang Zhung by expelling the Zhang's Bön priests from Yarlung. He was assassinated and Zhang Zhung continued its dominance of the region until it was annexed by Songtsen Gampo in the 7th century. Prior to Songtsän Gampo, the kings of Tibet were more mythological than factual, and there is insufficient evidence of their existence.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "QUESTION 4: How many satellites in the Beidou-1 constellation?\n",
            "\n",
            "  rank 1 | doc=Dog | para_index=27\n",
            "Dog communication is about how dogs \"speak\" to each other, how they understand messages that humans send to them, and how humans can translate the ideas that dogs are trying to transmit.:xii These communication behaviors include eye gaze, facial expression, vocalization, body posture (including movements of bodies and limbs) and gustatory communication (scents, pheromones and taste). Humans communicate with dogs by using vocalization, hand signals and body posture.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 2 | doc=Multiracial_American | para_index=17\n",
            "Prior to the one-drop rule, different states had different laws regarding color. More importantly, social acceptance often played a bigger role in how a person was perceived and how identity was construed than any law. In frontier areas, there were fewer questions about origins. The community looked at how people performed, whether they served in the militia and voted, which were the responsibilities and signs of free citizens. When questions about racial identity arose because of inheritance issues, for instance, litigation outcomes often were based on how people were accepted by neighbors.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 3 | doc=The_Blitz | para_index=10\n",
            "The deliberate separation of the Luftwaffe from the rest of the military structure encouraged the emergence of a major \"communications gap\" between Hitler and the Luftwaffe, which other factors helped to exacerbate. For one thing, Göring's fear of Hitler led him to falsify or misrepresent what information was available in the direction of an uncritical and over-optimistic interpretation of air strength. When Göring decided against continuing Wever's original heavy bomber programme in 1937, the Reichsmarschall's own explanation was that Hitler wanted to know only how many bombers there were, not how many engines each had. In July 1939, Göring arranged a display of the Luftwaffe's most advanced equipment at Rechlin, to give the impression the air force was more prepared for a strategic air war than was actually the case.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 4 | doc=Rule_of_law | para_index=3\n",
            "There has recently been an effort to reevaluate the influence of the Bible on Western constitutional law. In the Old Testament, there was some language in Deuteronomy imposing restrictions on the Jewish king, regarding such things as how many wives he could have, and how many horses he could own for his personal use. According to Professor Bernard M. Levinson, \"This legislation was so utopian in its own time that it seems never to have been implemented....\" The Deuteronomic social vision may have influenced opponents of the divine right of kings, including Bishop John Ponet in sixteenth-century England.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 5 | doc=Classical_music | para_index=5\n",
            "That said, the score does not provide complete and exact instructions on how to perform a historical work. Even if the tempo is written with an Italian instruction (e.g., Allegro), we do not know exactly how fast the piece should be played. As well, in the Baroque era, many works that were designed for basso continuo accompaniment do not specify which instruments should play the accompaniment or exactly how the chordal instrument (harpsichord, lute, etc.) should play the chords, which are not notated in the part (only a figured bass symbol beneath the bass part is used to guide the chord-playing performer). The performer and/or the conductor have a range of options for musical expression and interpretation of a scored piece, including the phrasing of melodies, the time taken during fermatas (held notes) or pauses, and the use (or choice not to use) of effects such as vibrato or glissando (these effects are possible on various stringed, brass and woodwind instruments and with the human voice).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "QUESTION 7: When did Beyoncé  receive ten nominations for the Grammy Awards?\n",
            "\n",
            "  rank 1 | doc=Buddhism | para_index=67\n",
            "The complete list of ten precepts may be observed by laypeople for short periods. For the complete list, the seventh precept is partitioned into two, and a tenth added:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 2 | doc=The_Blitz | para_index=4\n",
            "Within the Luftwaffe, there was a more muted view of strategic bombing. The OKL did not oppose the strategic bombardment of enemy industries and or cities, and believed it could greatly affect the balance of power on the battlefield in Germany's favour by disrupting production and damaging civilian morale, but they did not believe that air power alone could be decisive. Contrary to popular belief, the Luftwaffe did not have a systematic policy of what became known as \"terror bombing\". Evidence suggests that the Luftwaffe did not adopt an official bombing policy in which civilians became the primary target until 1942.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 3 | doc=American_Idol | para_index=19\n",
            "The finals are broadcast in prime time from CBS Television City in Los Angeles, in front of a live studio audience. The finals lasted eight weeks in season one, eleven weeks in subsequent seasons until seasons ten and eleven which lasted twelve weeks except for season twelve, which lasted ten weeks, and season thirteen, which lasted for thirteen weeks. Each finalist performs songs based on a weekly theme which may be a musical genre such as Motown, disco, or big band, songs by artists such as Michael Jackson, Elvis Presley or The Beatles, or more general themes such as Billboard Number 1 hits or songs from the contestant's year of birth. Contestants usually work with a celebrity mentor related to the theme. In season ten, Jimmy Iovine was brought in as a mentor for the season. Initially the contestants sing one song each week, but this is increased to two songs from top four or five onwards, then three songs for the top two or three.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 4 | doc=Gymnastics | para_index=12\n",
            "Individual routines in trampolining involve a build-up phase during which the gymnast jumps repeatedly to achieve height, followed by a sequence of ten bounces without pause during which the gymnast performs a sequence of aerial skills. Routines are marked out of a maximum score of 10 points. Additional points (with no maximum at the highest levels of competition) can be earned depending on the difficulty of the moves and the length of time taken to complete the ten skills which is an indication of the average height of the jumps. In high level competitions, there are two preliminary routines, one which has only two moves scored for difficulty and one where the athlete is free to perform any routine. This is followed by a final routine which is optional. Some competitions restart the score from zero for the finals, other add the final score to the preliminary results.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 5 | doc=High-definition_television | para_index=11\n",
            "The limited standardization of analog HDTV in the 1990s did not lead to global HDTV adoption as technical and economic constraints at the time did not permit HDTV to use bandwidths greater than normal television.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "QUESTION 10: With which goddess did Sulla, Pompey, and Julius Caesar all claim a special relationship?\n",
            "\n",
            "  rank 1 | doc=Education | para_index=26\n",
            "Educational psychology can in part be understood through its relationship with other disciplines. It is informed primarily by psychology, bearing a relationship to that discipline analogous to the relationship between medicine and biology. Educational psychology in turn informs a wide range of specialties within educational studies, including instructional design, educational technology, curriculum development, organizational learning, special education and classroom management. Educational psychology both draws from and contributes to cognitive science and the learning sciences. In universities, departments of educational psychology are usually housed within faculties of education, possibly accounting for the lack of representation of educational psychology content in introductory psychology textbooks (Lucas, Blazek, & Raley, 2006).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 2 | doc=Unicode | para_index=18\n",
            "Many scripts, including Arabic and Devanagari, have special orthographic rules that require certain combinations of letterforms to be combined into special ligature forms. The rules governing ligature formation can be quite complex, requiring special script-shaping technologies such as ACE (Arabic Calligraphic Engine by DecoType in the 1980s and used to generate all the Arabic examples in the printed editions of the Unicode Standard), which became the proof of concept for OpenType (by Adobe and Microsoft), Graphite (by SIL International), or AAT (by Apple).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 3 | doc=Computer | para_index=50\n",
            "A key component common to all CPUs is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 4 | doc=Sino-Tibetan_relations_during_the_Ming_dynasty | para_index=43\n",
            "With the example of the Ming court's relationship with the fifth Karmapa and other Tibetan leaders, Norbu states that Chinese Communist historians have failed to realize the significance of the religious aspect of the Ming-Tibetan relationship. He writes that the meetings of lamas with the Emperor of China were exchanges of tribute between \"the patron and the priest\" and were not merely instances of a political subordinate paying tribute to a superior. He also notes that the items of tribute were Buddhist artifacts which symbolized \"the religious nature of the relationship.\" Josef Kolmaš writes that the Ming dynasty did not exercise any direct political control over Tibet, content with their tribute relations that were \"almost entirely of a religious character.\" Patricia Ann Berger writes that the Yongle Emperor's courting and granting of titles to lamas was his attempt to \"resurrect the relationship between China and Tibet established earlier by the Yuan dynastic founder Khubilai Khan and his guru Phagpa.\" She also writes that the later Qing emperors and their Mongol associates viewed the Yongle Emperor's relationship with Tibet as \"part of a chain of reincarnation that saw this Han Chinese emperor as yet another emanation of Manjusri.\"\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 5 | doc=Symbiosis | para_index=8\n",
            "An example of mutual symbiosis is the relationship between the ocellaris clownfish that dwell among the tentacles of Ritteri sea anemones. The territorial fish protects the anemone from anemone-eating fish, and in turn the stinging tentacles of the anemone protect the clownfish from its predators. A special mucus on the clownfish protects it from the stinging tentacles.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "QUESTION 13: What area is considered to have a desert climate despite having an annual monsoon season?\n",
            "\n",
            "  rank 1 | doc=Mali | para_index=10\n",
            "Mali lies in the torrid zone and is among the hottest countries in the world. The thermal equator, which matches the hottest spots year-round on the planet based on the mean daily annual temperature, crosses the country. Most of Mali receives negligible rainfall and droughts are very frequent. Late June to early December is the rainy season in the southernmost area. During this time, flooding of the Niger River is common, creating the Inner Niger Delta. The vast northern desert part of Mali has a hot desert climate (Köppen climate classification (BWh) with long, extremely hot summers and scarce rainfall which decreases northwards. The central area has a hot semi-arid climate (Köppen climate classification (BSh) with very high temperatures year-round, a long, intense dry season and a brief, irregular rainy season. The little southern band possesses a tropical wet and dry climate (Köppen climate classification (Aw) very high temperatures year-round with a dry season and a rainy season.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 2 | doc=San_Diego | para_index=16\n",
            "San Diego is one of the top-ten best climates in the Farmers' Almanac and is one of the two best summer climates in America as scored by The Weather Channel. Under the Köppen–Geiger climate classification system, the San Diego area has been variously categorized as having either a semi-arid climate (BSh in the original classification and BSkn in modified Köppen classification) or a Mediterranean climate (Csa and Csb). San Diego's climate is characterized by warm, dry summers and mild winters with most of the annual precipitation falling between December and March. The city has a mild climate year-round, with an average of 201 days above 70 °F (21 °C) and low rainfall (9–13 inches [230–330 mm] annually). Dewpoints in the summer months range from 57.0 °F (13.9 °C) to 62.4 °F (16.9 °C).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 3 | doc=Alaska | para_index=8\n",
            "The climate in Southeast Alaska is a mid-latitude oceanic climate (Köppen climate classification: Cfb) in the southern sections and a subarctic oceanic climate (Köppen Cfc) in the northern parts. On an annual basis, Southeast is both the wettest and warmest part of Alaska with milder temperatures in the winter and high precipitation throughout the year. Juneau averages over 50 in (130 cm) of precipitation a year, and Ketchikan averages over 150 in (380 cm). This is also the only region in Alaska in which the average daytime high temperature is above freezing during the winter months.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 4 | doc=Portugal | para_index=29\n",
            "Portugal is defined as a Mediterranean climate (Csa in the South, interior, and Douro region; Csb in the North, Central Portugal and coastal Alentejo; mixed oceanic climate along the northern half of the coastline and also Semi-arid climate or Steppe climate (BSk in certain parts of Beja district far South) according to the Köppen-Geiger Climate Classification), and is one of the warmest European countries: the annual average temperature in mainland Portugal varies from 8–12 °C (46.4–53.6 °F) in the mountainous interior north to 16–19 °C (60.8–66.2 °F) in the south and on the Guadiana river basin. The Algarve, separated from the Alentejo region by mountains reaching up to 900 metres (3,000 ft) in Alto de Fóia, has a climate similar to that of the southern coastal areas of Spain or Southwest Australia.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  rank 5 | doc=Southeast_Asia | para_index=9\n",
            "The climate in Southeast Asia is mainly tropical–hot and humid all year round with plentiful rainfall. Northern Vietnam and the Myanmar Himalayas are the only regions in Southeast Asia that feature a subtropical climate, which has a cold winter with snow. The majority of Southeast Asia has a wet and dry season caused by seasonal shift in winds or monsoon. The tropical rain belt causes additional rainfall during the monsoon season. The rain forest is the second largest on earth (with the Amazon being the largest). An exception to this type of climate and vegetation is the mountain areas in the northern region, where high altitudes lead to milder temperatures and drier landscape. Other parts fall out of this climate because they are desert like.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Part 6: inspect matches for first 5 questions\n",
        "import pandas as pd\n",
        "\n",
        "# Make sure these are in memory (from earlier cells); if not, reload:\n",
        "# parsed_df = pd.read_csv(\"parsed.tsv\", sep=\"\\t\")\n",
        "# matches_df = pd.read_csv(\"question-matches.tsv\", sep=\"\\t\")\n",
        "# questions_df = pd.read_csv(\"questions.tsv\", sep=\"\\t\")\n",
        "\n",
        "first5_ids = sorted(questions_df[\"question_id\"].unique())[:5]\n",
        "\n",
        "for q_id in first5_ids:\n",
        "    q_text = questions_df.loc[\n",
        "        questions_df[\"question_id\"] == q_id, \"question\"\n",
        "    ].iloc[0]\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"QUESTION {q_id}: {q_text}\\n\")\n",
        "\n",
        "    sub = matches_df[matches_df[\"question_id\"] == q_id].sort_values(\n",
        "        \"question_rank\"\n",
        "    )\n",
        "\n",
        "    for _, row in sub.iterrows():\n",
        "        para = parsed_df[\n",
        "            (parsed_df[\"document_title\"] == row[\"document_title\"])\n",
        "            & (parsed_df[\"paragraph_index\"] == row[\"paragraph_index\"])\n",
        "        ][\"paragraph_context\"].iloc[0]\n",
        "\n",
        "        print(\n",
        "            f\"  rank {row['question_rank']} | \"\n",
        "            f\"doc={row['document_title']} | para_index={row['paragraph_index']}\"\n",
        "        )\n",
        "        print(para)\n",
        "        print(\"-\" * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHaFK8Z10xnS"
      },
      "source": [
        "Write a file \"worst-paragraphs.tsv\" with three columns question_id, document_title, paragraph_index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 7: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 8: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discussions</th>\n",
              "      <th>extra_libraries</th>\n",
              "      <th>generative_ai</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>Used OpenAI ChatGPT (GPT-5 Thinking) to help d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  discussions extra_libraries  \\\n",
              "0        none            none   \n",
              "\n",
              "                                       generative_ai  \n",
              "0  Used OpenAI ChatGPT (GPT-5 Thinking) to help d...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "ack_data = [{\n",
        "    \"discussions\": \"none\",\n",
        "    \"extra_libraries\": \"none\",\n",
        "    \"generative_ai\": (\n",
        "        \"Used OpenAI ChatGPT (GPT-5 Thinking) to help design and structure code \"\n",
        "        \"for the DX704 Week 10 project; I reviewed, ran, and adjusted all code myself.\"\n",
        "    ),\n",
        "}]\n",
        "\n",
        "ack_df = pd.DataFrame(ack_data)\n",
        "ack_df.to_csv(\"acknowledgements.tsv\", sep=\"\\t\", index=False)\n",
        "ack_df\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
